Benchmarks
==========

.. role:: raw-latex(raw)
    :format: latex html

.. raw:: html

    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

In this section, we compare the LIBTwinSVM library with other implementations in terms of classification accuracy and computational time. We conducted experiments on a PC with the following configuration:
	
.. table :: System configuration
	
	+---------+----------------------------+
	|   CPU   | AMD Ryzen 7 1800X @ 3.6GHz |
	+---------+----------------------------+
	|   RAM   |            16 GB           |
	+---------+----------------------------+
	|    OS   |      Ubuntu 18.04 LTS      |
	+---------+----------------------------+
	| Python  |             3.6            |
	+---------+----------------------------+
	
-----------------------
Classification accuracy
-----------------------
Here, we conducted experiments on benchmark datasets from the `UCI <https://archive.ics.uci.edu/ml/index.php>`_ machine learning repository. The feature values of all datasets were normalized in the range :raw-latex:`\(\left[0,1\right]\)`. For multi-classification, we chose One-vs-One scheme as it is often used in SVM packages. The characteristics of benchmark datasets are shown the table below:

.. table :: The characteristics of UCI benchmark datasets.
	
	+---------------------+------------------+------------------+------------------+
	| Datasets            |  # Samples       | # Features       |  # Class         |
	+=====================+==================+==================+==================+
	| Australian          |    690           |   14             |  2               | 
	+---------------------+------------------+------------------+------------------+
	| Bupa-Liver          |    345           |   6              |  2               |
	+---------------------+------------------+------------------+------------------+
	| Ionsphere           |    351           |   34             |  2               |
	+---------------------+------------------+------------------+------------------+
	| Monk3               |    554           |   6              |  2               |
	+---------------------+------------------+------------------+------------------+
	| WPBC                |    198           |   30             |  2               |
	+---------------------+------------------+------------------+------------------+
	| Hepatitis           |    155           |   19             |  2               |
	+---------------------+------------------+------------------+------------------+
	| Parkinson           |    195           |   22             |  2               |
	+---------------------+------------------+------------------+------------------+
	| Iris                |    150           |   4              |  3               |
	+---------------------+------------------+------------------+------------------+
	| Wine                |    178           |   13             |  3               |
	+---------------------+------------------+------------------+------------------+
	| Balance             |    625           |   4              |  3               |
	+---------------------+------------------+------------------+------------------+
	| Vehicle             |    846           |   18             |  4               |
	+---------------------+------------------+------------------+------------------+
	| Vowel               |    625           |   13             |  11              |
	+---------------------+------------------+------------------+------------------+
	
The classification performace of SVM and TSVM classifiers depends heavily on the choice of hyper-parameters. The optimal value of :raw-latex:`\(C\)` penalty parameter was selected from the set :raw-latex:`\( \{2^{i} \mid i=-5, -4, \dots, 4, 5\} \)`. In this experiment, the grid search method is used to find the optimal values of hyper-parameters. Table below shows the comparison of LIBTwinSVM with other implementations with linear kernel.
	
.. table :: The accuracy comparison of LIBTwinSVM with other implementations (Linear kernel).
	
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Datasets            |          LIBLINEAR                       |             LIBSVM                       |             LightTwinSVM              |        LIBTwinSVM (TSVM)                 |     LIBTwinSVM (LSTSVM)                  |
	+=====================+==========================================+==========================================+=======================================+==========================================+==========================================+
	| Australian          |   85.51 :raw-latex:`\(\pm\)` 0.02        |   87.25 :raw-latex:`\(\pm\)` 3.63        |   87.25 :raw-latex:`\(\pm\)` 3.63     |  **87.54** :raw-latex:`\(\pm\)` **2.12** | 87.39 :raw-latex:`\(\pm\)` 3.06          |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Bupa-Liver          |   68.41 :raw-latex:`\(\pm\)` 0.07        |  **70.43** :raw-latex:`\(\pm\)` **0.03** |   69.57 :raw-latex:`\(\pm\)` 2.43     |  69.86 :raw-latex:`\(\pm\)` 6.57         | **70.43** :raw-latex:`\(\pm\)` **2.98**  |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Ionsphere           |   88.03 :raw-latex:`\(\pm\)` 0.03        |    88.32 :raw-latex:`\(\pm\)` 0.04       |   88.90 :raw-latex:`\(\pm\)` 6.25     |  **90.02** :raw-latex:`\(\pm\)` **3.02** | **89.70** :raw-latex:`\(\pm\)` **5.58**  |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Monk3               |   77.62 :raw-latex:`\(\pm\)` 0.04        |    80.14 :raw-latex:`\(\pm\)` 0.06       |   85.56 :raw-latex:`\(\pm\)` 2.86     |  **86.28** :raw-latex:`\(\pm\)` **2.03** | **86.45** :raw-latex:`\(\pm\)` **5.70**  |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| WPBC                |   81.82 :raw-latex:`\(\pm\)` 0.05        |    81.31 :raw-latex:`\(\pm\)` 0.03       |   73.68 :raw-latex:`\(\pm\)` 6.33     |  77.81 :raw-latex:`\(\pm\)` 4.75         | **83.31** :raw-latex:`\(\pm\)` **3.57**  |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Hepatitis           |   81.29 :raw-latex:`\(\pm\)` 0.05        |    82.58 :raw-latex:`\(\pm\)` 0.02       |   83.23 :raw-latex:`\(\pm\)` 8.99     |  **83.87** :raw-latex:`\(\pm\)` **3.53** |   83.31 :raw-latex:`\(\pm\)` 3.57        |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Parkinson           |   76.92 :raw-latex:`\(\pm\)` 0.04        |    87.18 :raw-latex:`\(\pm\)` 0.03       |   82.05 :raw-latex:`\(\pm\)` 14.41    |  86.67 :raw-latex:`\(\pm\)` 5.94         |  **89.23** :raw-latex:`\(\pm\)` **4.97** |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Iris                |   95.33 :raw-latex:`\(\pm\)` 0.03        |    97.33 :raw-latex:`\(\pm\)` 0.02       |   96.00 :raw-latex:`\(\pm\)` 5.33     |  **98.67** :raw-latex:`\(\pm\)` **1.63** |  98.00 :raw-latex:`\(\pm\)` 2.67         |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Wine                |   98.31 :raw-latex:`\(\pm\)` 0.01        |    98.88 :raw-latex:`\(\pm\)` 0.01       |   96.65 :raw-latex:`\(\pm\)` 3.24     |  **99.43** :raw-latex:`\(\pm\)` **1.14** |  **99.43** :raw-latex:`\(\pm\)` **1.14** |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Balance             |   89.12 :raw-latex:`\(\pm\)` 0.02        | **91.68** :raw-latex:`\(\pm\)` **0.01**  |   90.24 :raw-latex:`\(\pm\)` 1.47     |  91.52 :raw-latex:`\(\pm\)` 0.82         |  87.68 :raw-latex:`\(\pm\)` 2.71         |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Vehicle             |   79.20 :raw-latex:`\(\pm\)` 0.03        |    80.26 :raw-latex:`\(\pm\)` 0.03       |   81.56 :raw-latex:`\(\pm\)` 2.19     |  **81.79** :raw-latex:`\(\pm\)` **3.16** |  81.44 :raw-latex:`\(\pm\)` 1.72         |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+
	| Vowel               |   57.88 :raw-latex:`\(\pm\)` 0.03        | **83.33** :raw-latex:`\(\pm\)` **0.01**  |   42.83 :raw-latex:`\(\pm\)` 7.97     |    75.96 :raw-latex:`\(\pm\)` 3.76       |  76.67 :raw-latex:`\(\pm\)` 1.17         |
	+---------------------+------------------------------------------+------------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+


	
------------------
Computational time
------------------
To analyze the computational efficieny of the LIBTwinSVM library, we conducted experiments on `NDC <http://research.cs.wisc.edu/dmi/svm/ndc/content.html>`_ datasets which were generated using David Musicant's NDC data generator. The characteristics of NDC datasets are shown in the table below:

.. table :: The characteristics of NDC datasets.
	
	+----------+----------------+------------+-----------+
	| Datasets | #Training data | #Test data | #Features |
	+----------+----------------+------------+-----------+
	|  NDC-5K  |      5,000     |     500    |     32    |
	+----------+----------------+------------+-----------+
	|  NDC-10K |     10,000     |    1000    |     32    |
	+----------+----------------+------------+-----------+
	|  NDC-25K |     25,000     |    2500    |     32    |
	+----------+----------------+------------+-----------+
	|  NDC-50K |     50,000     |    5000    |     32    |
	+----------+----------------+------------+-----------+
	|  NDC-1l  |     100,000    |   10,000   |     32    |
	+----------+----------------+------------+-----------+
	|  NDC-5l  |     500,000    |   50,000   |     32    |
	+----------+----------------+------------+-----------+
	|  NDC-1m  |    1,000,000   |   100,000  |     32    |
	+----------+----------------+------------+-----------+
	|          |                |            |           |
	+----------+----------------+------------+-----------+
	|          |                |            |           |
	+----------+----------------+------------+-----------+


.. table :: The comparison of LIBTwinSVM with other implementations in terms learning and prediction speed.

	+----------+------------------------+------------------------+------------------------+------------------------+
	| Datasets | LIBLINEAR              | LightTwinSVM           | LIBTwinSVM (TSVM)      | LIBTwinSVM (LSTSVM)    |
	+          +------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	|          | Train time | Test time | Train time | Test time | Train time | Test time | Train time | Test time |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-5K   | 0.27       | 0.0048    | 0.57       | 0.012     | 0.63       | 0.00037   | 0.0025     | 0.00032   |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-10K  | 0.70       | 0.0063    | 2.21       | 0.024     | 2.47       | 0.00062   | 0.0047     | 0.00067   |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-25K  | 2.94       | 0.0069    | 13.99      | 0.055     | 15.69      | 0.0016    | 0.013      | 0.0019    |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-50K  | 7.87       | 0.0025    | 56.39      | 0.087     | 63.85      | 0.062     | 0.021      | 0.0022    |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-1l   | 19.01      | 0.0059    |            |           |            |           | 0.038      | 0.0047    |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-5l   | 132.93     |  0.013    |            |           |            |           | 0.20       | 0.041     |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	| NDC-1m   | 289.36     |  0.018    |            |           |            |           | 0.38       | 0.074     |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	|          |            |           |            |           |            |           |            |           |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+
	|          |            |           |            |           |            |           |            |           |
	+----------+------------+-----------+------------+-----------+------------+-----------+------------+-----------+	
	
	